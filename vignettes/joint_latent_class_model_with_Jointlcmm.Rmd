---
title: "How to estimate a joint latent class mixed model using Jointlcmm function"
output: 
  rmarkdown::html_vignette:
    toc: true # table of content true
    toc_depth : 3
vignette: >
  %\VignetteIndexEntry{Joint latent class model with Jointlcmm}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
library(lcmm)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
&nbsp;


# Background on the model 

<p align="justify"> Joint models are used to analyse simultaneously two related phenomena, the evolution of a variable and the occurence of an event. Joint latent class models (JLCM) consist of a linar mixed model and a proportional hazard model linked by the latent classes. The population is split in several groups, the latent classes, and each class is caracterized by a specific evolution of the dependent variable and an associated risk of event.


&nbsp;


<p align="justify">Latent class membership is defined by a discrete random variable $c_{i}$ that equals $g$ if subject $i$ belongs to latent class $g$ ($g$ = 1, ...,$G$). The variable $c_{i}$ is latent; its probability is described using a multinomial logistic model according to covariates $X_{ci}$:

$\pi_{ig}= P(c_{i} = g|X_{ci}) = \frac{\exp(\xi_{0g}+X_{ci}\xi_{1g})}{ \sum_{l=1}^{G}\exp(\xi_{0l}+X_{ci}\xi_{1l})}$

where $\xi_{0g}$ is the intercept for class $g$ and $\xi_{1g}$ is the q1-vector of class-specific parameters associated with the q1-vector of time-independent covariates $X_{ci}$. For identifiability, $\xi_{0G} = 0$ and $\xi_{1G} = 0$. When no covariate predicts the latent class membership, this model reduces to a class-specific probability.</p>


<p align="justify">For a continuous and Gaussian variable, the trajectories of $Y$ are defined conditionally to the latent class by a linear mixed model. So, conditional on class $g$, the model is defined for subject $i$ at occasion $j$:</p>
  

&nbsp;

$$Y_{ij}|_{c_{i}=g} = X_{2ij}\beta+X_{3ij}\gamma_{g}+Z_{ij}b_{i}+\epsilon_{ij}$$ 

&nbsp;

<p align="justify">where $X_{2ij}$, $X_{3ij}$ and $Z_{ij}$ are vectors of covariates respectively associated with common fixed effects over classes $\beta$, class-specific fixed effects $\gamma_{g}$ and with individual random effects $b_{i}|_{ci=g}$ called $b_{ig}$ whose distributions are now class-specific. $X_{2}$ and $X_{3}$ can't have common variables. </p> 

<p align="justify">The proporional hazard model is defined conditionaly on the same class $g$ as :</p>
  

&nbsp;

$$\lambda(t)|_{c_{i}=g} = \lambda_{0g}(t)\exp(X_{4i}\psi+X_{5i}\eta_g)$$ 

&nbsp;

<p align="justify">where $X_{4i}$ and $X_{5i}$ are vectors of covariates respectively associated with common effects aver classes $\psi$ and class-specific effects $\eta_g$. </p>

# Data

We use the paquid sample included in the package. Please refer to the introduction vignette for more details about these data. We consider here only the subjects at risk of dementia at the begining of the study :

```{r, include=T}
paquidS <- paquid[which(paquid$agedem > paquid$age_init),]
```

We laso create some variables that will be used in the example :

```{r, include=T}
library(NormPsy)
paquidS$normMMSE <- normMMSE(paquidS$MMSE)
paquidS$age65 <- (paquidS$age-65)/10
```


# First use of Jointlcmm function

We model jointly the trajectory of normMMSE and time to dementia. 
As a JLCM is estimated for a fixed number of latent classes, we begin by specifying the model with 1 latent class. 

## 1. Linear mixed model for normMMSE trajectory

We begin by specifying the linear mixed model for normMMSE. We will consider the same specification as in the hlme vignette, that is a quadratic trajectory with age adjusted for CEP.

```{r, include=T}
lmm <- hlme(normMMSE ~ age65 + I(age65^2) + CEP , random =~ age65 + I(age65^2), 
             subject = 'ID', data = paquidS,verbose=FALSE)
summary(lmm)
```


## 2. Survival model for dementia diagnosis

Joinlcmm assumes a parametric baseline risk function. We thus need to determine the family of baseline risks. To do so, we will use the jointlcmm function in which the longitudinal part will be the same as in hlme. 

In the application, the risk of dementia is described according to age so we have a problem of delayed entry. The program handles it by specifying age_init in the Surv object. 

We try different families of baseline risks (Weibull, Splines, piecewise constant) and we systematically adjust on CEP and male.

```{r, include=T,eval=F}
# Weibull distribution
mj1 <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, random =~ age65 + I(age65^2), 
                 survival = Surv(age_init, agedem, dem) ~ CEP + male, hazard = "Weibull",
                 subject = 'ID', data = paquidS)
mj1$best
# Note that to reduce computation time, we could fix the parameters of the longitudinal 
#part to those of the linear mixed model 
binit <- c(1,1,1,1,lmm$best)
mj1bis <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, random =~ age65 + I(age65^2),
                    survival = Surv(age_init, agedem, dem) ~ CEP + male, hazard = "Weibull",
                    subject = 'ID', data = paquidS,B=binit, posfix=5:15)
# Piecewise constant hazard
mjP1 <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, random =~ age65 + I(age65^2),
                  survival = Surv(age_init, agedem, dem) ~ CEP + male, hazard = "piecewise",
                  subject = 'ID', data = paquidS)
# Hazard approximated by cubic splines (3 intern knots located at the quantiles by default
mjS1 <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, random =~ age65 + I(age65^2),
                  survival = Surv(age_init, agedem, dem) ~ CEP + male, hazard = "splines",
                  subject = 'ID', data = paquidS)
```

The Weibull model gives the best fit. 

```{r, include=T}
# From the summary table, we prefer the Weibull model
summarytable(mj1,mjP1,mjS1)
summarytable(mj1,mjP1,mjS1,which=c("npm","loglik","AIC"))
# Summary of the model
summary(mj1)
```
It is possible to change the parameterization of the survival model (with log instead of +/-sqrt)

```{r, include=T,eval=F}
binit <- c(1,1,1,1,lmm$best)
mj1ter <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, random =~ age65 + I(age65^2),
                    survival = Surv(age_init, agedem, dem) ~ CEP + male, hazard = "Weibull",
                    subject = 'ID', data = paquidS,B=binit, posfix=5:15,logscale = TRUE)
# Same loglikelihood, HR, only the parameters of the baseline risk function change.
summary(mj1ter)
```


## 3. Estimation with different numbers of latent classes

Once the specification of the model under G=1 is done (one class means independent models), we can estimate the model with more than one class. 

This is a cumbersome step in the analysis since the estimation has to be replicated for different numbers of latent classes AND various initial values to avoid the convergence toward a local maximum. 


### 3.1  Model with two latent classes

```{r, include=T,eval=F}
# Model with 2 latent classes and class-specific baseline risks
# The starting values are determined by the model under G=1
# CAUTION: Try to specify argument B=. Otherwise, the program internally estimated a 
# first model with G=1 which artificially makes the program longer. 
mj2 <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, mixture =~ age65 + I(age65^2), 
                 random =~ age65 + I(age65^2), survival = Surv(age_init, agedem, dem) 
                 ~ CEP
                 + male, hazard = "Weibull", subject = 'ID', data = paquidS, ng=2,B=mj1)
# model with 2 latent classes and proportional hazards in each class
mj2_prop <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, mixture =~ age65 + I(age65^2),
                      random =~ age65 + I(age65^2), survival = Surv(age_init, agedem, dem)
                      ~ CEP + male, hazard = "Weibull", subject = 'ID', data = paquidS,
                      ng=2,B=mj1, hazardtype='PH')
# comparison
summarytable(mj2,mj2_prop,which=c("npm","loglik","AIC"))
```

We could choose to consider proportional hazards given the fit obtained but we continue with class-specific baseline risk functions to allow for more flexibility. Note that the results in terms of classification seem to be very close. 

```{r, include=T}
# Classification given in
head(mj2$pprob)
# comparison of classifications
xclass(mj2,mj2_prop)
```

The estimates of the model are in the summary. 

```{r, include=T}
# summary of the model
summary(mj2)
```

From this first model, we can look at different output functions available in the package to evaluate the quality of fit of the model. 

```{r, include=T,eval=F}
# quality of the classification
postprob(mj2)
# residuals
plot(mj2)
# fit of the longitudinal model: marginal predictions
plot(mj2,which="fit",var.time="age")
# fit of the longitudinal model: subject-specific predictions
plot(mj2,which="fit",var.time="age",marg=FALSE)
```

And the predictions of the model:

```{r, include=T,eval=F}
# plot of the baseline risk functions and survival functions
plot(mj2,which="baselinerisk",var.time="age")
plot(mj2,which="survival",var.time="age")
```

The model obtained with the first call of jointlcmm is not necessarily the maximum likelihood estimator for 2 classes. The model must be refitted with other initial values. There are different possibilities in the package:

- random departure from the asymptotic distribution of the estimates under G=1

- initial values chosen by the user

- a grid search with replicates R times the random departures with a maximu of M iterations of the algorithm each time. The program finishes the estimation with the departure which gave the best log likelihood after the M iterations. This is what is recommended with latent class models to ensure the convergence toward the global maximum. 

The grid search can take a lot of time as replicating R model estimation. I recommend to use 100 random departures and if possible between 30-50 iterations. Here, we will illustrate the procedure with less replicates and iterations to reduce the processing time. 

```{r, include=T,eval=F}
# model with 2 latent classes and class-specific risk functions.
# multiple departures using a grid search 
# (here, only a small gridsearch with 15 replicates and 10 iterations 
# we recommend more replicated -50 to 100- and 30 iterations) 
# Be careful, this might take a lot of time !!
mj2b <- gridsearch(rep = 15, maxiter = 10, minit = mj1, Jointlcmm(normMMSE ~ age65 +
        I(age65^2) + CEP, mixture =~ age65 + I(age65^2), random =~ age65 + I(age65^2),
        survival = Surv(age_init, agedem, dem) ~ CEP + male, hazard = "Weibull", 
        subject = 'ID', data = paquidS, ng=2,verbose=F))

# An alternative is to directly choose the initial values and explore different 
# plausible departures. 
# The order of the B vector is the same as in the summary.
# Below, I keep the variance covariance parameters as in G=1. The other parameters are 
# chosen according to values obtained above. 
binit <- c(0,0.10,5,0.11,5.1,0,0,70,60,3,8,0,-5,13,mj1$best[9:15])
mj2c <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, mixture =~ age65 + I(age65^2), 
                  random =~ age65 + I(age65^2), survival = Surv(age_init, agedem, dem)
                  ~ CEP + male, hazard = "Weibull", subject = 'ID', data = paquidS,
                  ng=2,B=binit)
# We can also start with a random departure:
mj2d <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, mixture =~ age65 + I(age65^2), 
                  random =~ age65 + I(age65^2), survival = Surv(age_init, agedem, dem)
                  ~ CEP + male, hazard = "Weibull", subject = 'ID', data = paquidS,
                  ng=2,B=random(mj1))

```

In this example, we always converge to the same maximum whatever the departure but the latent classes might be exchanged. 

```{r, include=T}
# Comparison of the model estimations
summarytable(mj2,mj2b,mj2c,mj2d)
```

### 3.2  Model with more than 2 latent classes

Estimation of the models with 3 and 4 classes from default values (based on G=1 model estimates).


```{r, include=T,eval=F}
mj3 <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, mixture =~ age65 + I(age65^2),
                 random =~ age65 + I(age65^2), survival = Surv(age_init, agedem, dem) 
                 ~ CEP + male, hazard = "Weibull", subject = 'ID', data = paquidS, 
                 ng = 3, B = mj1) 

mj4 <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, mixture =~ age65 + I(age65^2),
                 random =~ age65 + I(age65^2), survival = Surv(age_init, agedem, dem) 
                 ~ CEP + male, hazard = "Weibull", subject = 'ID', data = paquidS, 
                 ng = 4, B = mj1,verbose=F) 

```

The program did not converge properly after 100 iterations (the maximum number of iterations specified by default). This is explained by the fact that the program converged to an non optimal point (local maximum). Indeed, when looking at the results (loglikelihood and estimates), the model mj3 converged toward the 1 class model and the model mj4 converged toward the 2 class model. 

```{r, include=T}
summarytable(mj1,mj2,mj3,mj4)
```

Such a problem may happen and the user should be careful with this issue. We can use other initial values to search for the global maximum in another part of the parameter space: 

```{r, include=T,eval=F}
# For 3 classes, we need 6 additional parameters compared to the 2 class model: 
# 1 proba + 2 Weibull + 3 polynomial parameters. 

Binit <- rep(0, length(mj2$best) + 6)
Binit[c(2, 5:10, 12, 13, 15, 16, 18, 19:(length(Binit)))] <- mj2$best
Binit[c(1, 3, 4, 11, 14, 17)] <- c(0, 0.11, 4, 70, 0, 0)
mj3b <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, mixture =~ age65 + I(age65^2), 
                  random =~ age65 + I(age65^2), survival = Surv(age_init, agedem, dem)
                  ~ CEP + male, hazard = "Weibull", subject = 'ID', data = paquidS, 
                  ng = 3, B = Binit) 

# For the 4 class model, we can start from the three class model:
Binit <- rep(0, length(mj3b$best) + 2 + 3 + 1)
Binit[c(1, 2, 4:7, 10:15, 17:19, 21:23, 25:length(Binit))] <- mj3b$best
Binit[c(3, 8, 9, 16, 20, 24)] <- c(0, 0.1, 10, 60, 5, -10)
mj4b <- Jointlcmm(normMMSE ~ age65 + I(age65^2) + CEP, mixture =~ age65 + I(age65^2),
                  random =~ age65 + I(age65^2), survival = Surv(age_init, agedem, dem) 
                  ~ CEP + male, hazard = "Weibull", subject = 'ID', data = paquidS, 
                  ng = 4, B = Binit) 

# The best way is to use the grid search (although for the class, we consider only 
# 10 replicates and 15 iterations at max so that it is not too long)
# But it is always better to try more random departures and iterations. 
# 3 class model with gridsearch
mj3c <- gridsearch(rep = 10, maxiter = 15, minit = mj1, Jointlcmm(normMMSE ~ age65 +
                  I(age65^2) + CEP, mixture =~ age65 + I(age65^2), random =~ age65 +
                    I(age65^2), survival = Surv(age_init, agedem, dem) ~ CEP + male,
                   hazard = "Weibull", subject = 'ID', data = paquidS, ng =3)) 
 
# 4 class model with gridsearch
mj4c <- gridsearch(rep = 10, maxiter = 15, minit = mj1, Jointlcmm(normMMSE ~ age65 +
                  I(age65^2) + CEP, mixture =~ age65 + I(age65^2), random =~ age65 +
                    I(age65^2), survival = Surv(age_init, agedem, dem) ~ CEP + male,
                  hazard = "Weibull", subject = 'ID', data = paquidS, ng = 4),verbose=F)
```

From the summary, we choose the 4 class model. 

```{r, include=T}
# summarytable by default
summarytable(mj1,mj2,mj3,mj3b,mj3c,mj4,mj4b,mj4c)
# summary table with other measures for those who converged: 
summarytable(mj1,mj2,mj3c,mj4b,which=c("npm","conv","loglik","BIC","SABIC","entropy","scoretest"))
tab <- summarytable(mj1,mj2,mj3c,mj4b,which=c("npm","loglik","BIC","SABIC","entropy"))
# plots
ng <- 1:4
par(mfrow=c(1,2))
plot(tab[,"BIC"] ~ ng,type="l",bty='n')
plot(tab[,"entropy"] ~ ng,type="l",bty='n')
# score test statistics for the independence assumption
ST <- c(mj1$scoretest[1],mj2$scoretest[1],mj3c$scoretest[1],mj4b$scoretest[1]) 
plot(ST ~ ng,type="l",bty='n')
```

The score test statistics rejects the conditional independence at the 5% level but the shape of the curve of ST according to the number of class (with the asymptot) tells us that we will probably never reach the significance level.



## 4. Analysis of the results with the 4 class model

## 4.1. Summary of the estimation

The summary gives all the important information 

```{r, include=T}
summary(mj4b)
```

## 4.2. Evaluation of the classification

A major element of joint latent class models is the posterior classification, and the discriminatory power of this classification. 

```{r, include=T}
# table with the posterior classification
head(mj4b$pprob)
# output for classification evaluation
postprob(mj4b)
```

## 4.3 Graphs for the fit

We can assess the fit of the model by comparing the predictions to the observations by time intervals. 

```{r, include=T}
# overall
plot(mj4b, which = "fit", var.time = "age65", marg = F, break.times = 10, bty = "l", 
     ylab = "normMMSE", xlab = "Age in decades from 65 years",shades=T)
# by covariate profile
par(mfrow=c(1,2))
plot(mj4b, which = "fit", var.time = "age65", marg = F, break.times = 10, bty = "l", 
     ylab = "normMMSE", xlab = "Age in decades from 65 years",subset = dem == 1,
     main="diagnosed as demented",shades=T)
plot(mj4b, which = "fit", var.time = "age65", marg = F, break.times = 10, bty = "l", 
     ylab = "normMMSE", xlab = "Age in decades from 65 years",subset = dem == 0,
     main="non diagnosed as demented",shades=T)
```

The residuals of the longitudinal part:

```{r, include=T}
plot(mj4b)
```


For the survival part, predictive survival can be compared to a weighted kaplan-meier but this is not automatic yet in the package. It needs to be programmed manually so we will not see it today. 


<!-- ```{r, include=T} -->
<!-- # Comparison with Kaplan-Meier -->
<!-- require(survey) -->
<!-- s <- list(NULL) -->

<!-- paquidS_unique<-paquidS[-which(duplicated(paquidS$ID)==T),] -->
<!-- for (g in 1:4){ -->
<!--   prob <- mj4b$pprob[,2+g] -->
<!--   names(prob) <- "prob" -->
<!--   psaKM <- cbind(paquidS_unique,prob) -->
<!--   dpbc<-svydesign(id=~ID,weights=~prob, data=psaKM) -->
<!--   s[[g]]<-svykm(Surv(agedem,dem)~1, design=dpbc) -->
<!--   lines( s[[g]],col=g) -->
<!--   plot(s[[g]],lwd=2,col=color[g],bty="l",ylim=ylim,xlim=xlim1,xlab="" -->
<!--        ,lty=1,pch=2,ylab="") -->
<!--   par(new=TRUE) -->
<!-- } -->
<!-- ``` -->




## 4.4. Graph of predicted trajectories according to a profile of covariates

```{r, include=T}
datnew <- data.frame(age65 = seq(0, 3, length=100))
datnew$male <- 0
datnew$CEP <- 0
# computation of the predictions
mj4b.pred <- predictY(mj4b, newdata = datnew, var.time = "age65")
plot(mj4b.pred, bty = "l", ylim = c(0, 80), legend.loc = "bottomleft",
     ylab = "normMMSE", xlab = "age in decades from 65 years", lwd = 2)
```


## 4.5. Graph of predicted cumulative incidence according to a profile of covariates


```{r, include=T}
# graph of predicted survival trajectory for the reference group
plot(mj4b, which = "survival", lwd = 2, legend.loc = F, bty = "l",
     xlab = "age in years", ylab = "dementia-free probability")

# computation of the cumulative incidence for a specific profile of covariates
cuminc0 <- cuminc(mj4b,time = seq(65,95,by=1))
cuminc1 <- cuminc(mj4b,time = seq(65,95,by=1),CEP=1,male=1)
# plot of cumulative incidences
par(mfrow=c(1,2))
plot(cuminc0,title="CEP=0 and male=0")
plot(cuminc1,lty=2,title="CEP=1 and male=1")

```



# C. To go further ...

## 1. Individual dynamic prediction

The joint latent class model can be used to provide individual dynamic prediction of the event from the observed repeated measures of the marker. This is usually done for a "new" subject (not in the estimation data) but for the class, we focus on subject 72:

```{r, include=T}
paq72 <- paquidS[which(paquidS$ID == 72), ]
# prediction computation
dynp <- dynpred(mj4b, paq72, landmark = c(80, 90), var.time = "age65", 
                horizon = c(1, 3, 5, 8, 9), fun.time = function(x) { 10 * x + 65 }, 
                draws = TRUE)
# graph of predictions
plot(dynp, landmark = 80, ylim = c(55, 85, 0, 1), col = c(1,2), pch = 20,
     ylab = "normMMSE", main = "At landmark age 80", xlab = "age in years")
plot(dynp, landmark = 90, ylim = c(55, 85, 0, 1), col = c(1,2), pch = 20,
     ylab = "normMMSE", main = "At landmark age 90", xlab = "age in years")

```


When the objective is to provide dynamic predictions, the predictive power of the model should be specifically checked using appropriate techniques. 
The package has an internal measure, the EPOCE which quantifies the pronostic information. For measures such as the AUC or Brier Score, other packages can be used from the dynamic predictions obtained with Jointlcmm, for instance timeROC (Blanche et al., Biometrics 2015). 

Here is an example of the use of EPOCE: 

```{r, include=T,message=F,eval=F}
# definition of the prediction times
landmark <- c(70, 72, 75, 77, 80, 82, 85, 87, 90)
# calculation of the measure for each model. Be careful with the function which links 
# the time in the longitudinal model and the time in the survival model (fun.time)
epoce1 <- epoce(mj1, pred.times = landmark, var.time = "age65",fun.time = 
                  function(x) { 10 * x + 65 })
epoce2 <- epoce(mj2, pred.times = landmark, var.time = "age65",fun.time = 
                  function(x) { 10 * x + 65 })
epoce3 <- epoce(mj3b, pred.times = landmark, var.time = "age65",fun.time = 
                  function(x) { 10 * x + 65 })
epoce4 <- epoce(mj4b, pred.times = landmark, var.time = "age65",fun.time = 
                  function(x) { 10 * x + 65})
```


```{r, include=T,message=F}
# computation of the differences in EPOCE
diff23 <- Diffepoce(epoce2, epoce3)
diff34 <- Diffepoce(epoce3, epoce4)
# and the graphs for the results
par(mfrow = c(1, 2))
plot(epoce1, ylim = c(0.5, 1.5), main = "cross-validated EPOCE estimates",bty = "l")
plot(epoce2, add = TRUE, col = 2, lty = 2)
plot(epoce3, add = TRUE, col = 3, lty = 3)
plot(epoce4, add = TRUE, col = 4, lty = 4)
legend("topright", legend = c("G=1", "G=2", "G=3", "G=4"), col = 1:4,lty = 1:4, 
       bty = "n")
plot(diff23, main = "Difference in EPOCE estimates", lty = c(1, 2, 2),pch = 20, 
     ylim = c(-0.05, 0.30), bty = "l")
plot(diff34, add = T, main = "Difference in EPOCE estimates", col = 4,
     lty = c(1, 2, 2), pch = 18)
legend("topleft", legend = c("G=2/G=3", "G=3/G=4", "95%TI", "95%TI"),
       ncol = 2, col = c(1, 4, 1, 4), lty = c(1, 1, 2, 2), pch = c(20, 18, 20, 18), 
       bty = "n")
```

Here the model with 3 latent classes seems to have a better predictive power than the 4 class model.

## 2. Competing risks

Jointlcmm function can account for competing risks with the same structure of call. The only difference is in the definition of the time to event which is the minimum time between all the causes of event and the censoring. The indicator of event also indicates 0 for censoring or k for cause k. 
Suppose we have further information in the paquidS sample, namely a variable Age_CR that includes the first event between dementia and death, and Indic_CR that indicates the cause of event, dementia or death before dementia. In the following we give some examples of joint latent class models with competing risks.

```{r, include=T,eval=F}
# model with G=1 with Weibull for both events
mj1_CR <- Jointlcmm(normMMSE ~ age65+I(age65^2) + CEP, random =~  age65+I(age65^2), 
                         survival = Surv(age_init, Age_CR, Indic_CR) ~ CEP + male, 
                         hazard = "Weibull", subject = 'ID', data = paquidS_CR, ng = 1)
```

In the regression, we can consider specific effects with cause() :

```{r, include=T,eval=F}
# model with G=1 and cause-specific effects of CEP and male
mj1_CR_CS <- Jointlcmm(normMMSE ~ age65+I(age65^2) + CEP, random =~ age65+I(age65^2), 
                 survival = Surv(age_init, Age_CR, Indic_CR)  ~ cause(CEP) 
                + cause(male), hazard = "Weibull", subject = 'ID', data = paquidS_CR, 
                ng = 1,verbose=F)

```

Note that different baseline risk functions can be considered for the two events:

```{r, include=T,eval=F}
mj1_CR_WS <- Jointlcmm(normMMSE ~ age65+I(age65^2) + CEP, random =~  age65+I(age65^2), 
                         survival = Surv(age_init, Age_CR, Indic_CR) ~ CEP + male, 
                         hazard = c("Weibull","splines"), subject = 'ID', data = paquidS_CR, ng = 1)
summary(mj1_CR_WS)
```

We can now use the same technique of estimation with G>1 for this model with competing risks ...

